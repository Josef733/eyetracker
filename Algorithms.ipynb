{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "single-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aggressive-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= []\n",
    "\n",
    "time = []\n",
    "\n",
    "curr_X = []\n",
    "curr_Y = []\n",
    "\n",
    "delta_X = []\n",
    "delta_Y = []\n",
    "\n",
    "delta_time = []\n",
    "\n",
    "disp = []\n",
    "\n",
    "nonX = []\n",
    "nonY = []\n",
    "nonS = []\n",
    "\n",
    "\n",
    "for i in range(2,3):\n",
    "    participant = i\n",
    "    zeros = 4 - len(str(participant))\n",
    "    data.append(pd.read_csv(\"data\\Participant\"+ zeros*'0' + str(participant) + \".tsv\",sep=\"\\t\"))\n",
    "\n",
    "\n",
    "    time.append(data[-1]['Eyetracker timestamp'])\n",
    "    curr_X.append(data[-1]['Gaze point X'])\n",
    "    curr_Y.append(data[-1]['Gaze point Y'])\n",
    "    delta_X.append(np.diff(curr_X[-1]))\n",
    "    delta_Y.append(np.diff(curr_Y[-1]))\n",
    "    delta_time.append(np.diff(time[-1]))\n",
    "    disp.append(np.sqrt(np.diff(curr_X[-1])**2 + np.diff(curr_Y[-1])**2))\n",
    "    #speed.append(disp[-1]/delta_time[-1])\n",
    "\n",
    "    #remove NaN/missing\n",
    "    #nonX.append(d_X[-1][np.logical_not(np.isnan(d_X[-1]))])\n",
    "    #nonY.append(d_Y[-1][np.logical_not(np.isnan(d_Y[-1]))])\n",
    "    #nonS.append(d_S[-1][np.logical_not(np.isnan(d_S[-1]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "patent-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data\\Participant\"+ zeros*'0' + str(participant) + \".tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minimal-australia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46556\n",
      "46556\n"
     ]
    }
   ],
   "source": [
    "x_val = test.iloc[:, 39:40].values\n",
    "y_val = test.iloc[:, 40:41].values\n",
    "\n",
    "print(len(x_val))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Duration\n",
    "\n",
    "print(\"Timestamps\")\n",
    "#print(fix_timestamp)\n",
    "\n",
    "fix_duration_diff = []\n",
    "\n",
    "#Print diff in timestamps for easy feature seperation\n",
    "\n",
    "for i in range(len(fix_timestamp)-1):\n",
    "    \n",
    "    fix_duration_diff.append(fix_timestamp[i+1] - fix_timestamp[i])\n",
    "\n",
    "#print(fix_duration_diff)\n",
    "#print(len(fix_duration_diff))\n",
    "\n",
    "# Feature Displacement\n",
    "\n",
    "fix_point_disP = []  \n",
    "x_point_fixLen = []\n",
    "y_point_fixLen = []\n",
    "    \n",
    "for i in range(len(x_fix)-1):\n",
    "    \n",
    "    x_point_fixLen.append(x_fix[i+1] - x_fix[i])\n",
    "    \n",
    "    y_point_fixLen.append(y_fix[i+1] - y_fix[i])\n",
    "        \n",
    "    fix_point_disP.append(np.sqrt(x_point_fixLen[i]**2 + y_point_fixLen[i]**2))\n",
    "\n",
    "#Define boundaries for feature seperation (a certain amount of time needs to pass for a feature to be \"ended\")\n",
    "\n",
    "fix_duration_lengths = []\n",
    "fix_disp_lengths = []\n",
    "\n",
    "fix_feat_disp = 0 \n",
    "\n",
    "fix_count = 0\n",
    "fix_duration_set = 0\n",
    "\n",
    "\n",
    "fix_disP = []  \n",
    "x_fixLen = []\n",
    "y_fixLen = []\n",
    "    \n",
    "for i in range(len(x_fix)-1):\n",
    "    \n",
    "    x_fixLen.append(x_fix[i+1] - x_fix[i])\n",
    "    \n",
    "    y_fixLen.append(y_fix[i+1] - y_fix[i])\n",
    "        \n",
    "    fix_disP.append(np.sqrt(x_fixLen[i]**2 + y_fixLen[i]**2))\n",
    "    \n",
    "    \n",
    "fix_theta_np = []\n",
    "\n",
    "ang_time_f2 = []\n",
    "\n",
    "fix_duration_diff_corr = []\n",
    "\n",
    "for i in range(len(fix_duration_diff)-1):\n",
    "    vec1 = [np.array(x_fixLen[i]).sum(axis=0), np.array(y_fixLen[i]).sum(axis=0)]\n",
    "    vec2 = [np.array(x_fixLen[i+1]).sum(axis=0), np.array(y_fixLen[i+1]).sum(axis=0)]\n",
    " \n",
    "    unit1 = vec1 / np.linalg.norm(vec1)\n",
    "    unit2 = vec2 / np.linalg.norm(vec2)\n",
    "    dot_product = np.dot(unit1, unit2)\n",
    "    #print(np.arccos(dot_product))\n",
    "    \n",
    "    if (math.isnan(np.arccos(dot_product))):\n",
    "        pass\n",
    "    else:\n",
    "        fix_theta_np.append(math.pi - np.arccos(dot_product))\n",
    "        ang_time_f2.append(fix_timestamp[i+1]/1000000)\n",
    "        fix_duration_diff_corr.append(fix_duration_diff)\n",
    "        \n",
    "print(len(fix_theta_np))\n",
    "\n",
    "print(len(fix_duration_diff_corr))\n",
    "\n",
    "#print(fix_duration_diff)\n",
    "        \n",
    "#print(len(fix_duration_diff_corr))\n",
    "\n",
    "fix_theta_np_avg = 0\n",
    "\n",
    "fix_feat_theta_avg = []\n",
    "        \n",
    "for i in range (len(fix_duration_diff_corr)):\n",
    "    \n",
    "    if (fix_duration_diff[i] < 100000):\n",
    "        fix_count = fix_count + 1\n",
    "        #count up individual lengths\n",
    "        \n",
    "        if (fix_duration_diff[i] < 0):\n",
    "            pass\n",
    "        else:\n",
    "            fix_duration_set = fix_duration_set + fix_duration_diff[i]\n",
    "            fix_feat_disp = fix_feat_disp + fix_point_disP[i]\n",
    "            fix_theta_np_avg = fix_theta_np_avg + fix_theta_np[i]\n",
    "    \n",
    "        #print(fix_duration_diff[i])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        if (fix_count <= 1):\n",
    "            #discard\n",
    "            #print(fix_count)\n",
    "            fix_count = 0 #reset\n",
    "            fix_duration_set = 0\n",
    "            fix_feat_disp = 0\n",
    "            \n",
    "        else:\n",
    "            #append\n",
    "            #print(fix_count)\n",
    "            fix_duration_lengths.append(fix_duration_set)\n",
    "            fix_duration_set = 0\n",
    "            fix_disp_lengths.append(fix_feat_disp)\n",
    "            fix_feat_theta_avg.append(fix_theta_np_avg/fix_count)\n",
    "            fix_theta_np_avg = 0\n",
    "            fix_feat_disp = 0\n",
    "            fix_count = 0 #reset \n",
    "        \n",
    "print(len(fix_feat_theta_avg))\n",
    "        \n",
    "plt.hist(fix_feat_theta_avg)\n",
    "plt.show()\n",
    "        \n",
    "#print(count)\n",
    "    \n",
    "#print(len(fix_duration_lengths))\n",
    "\n",
    "#print(fix_duration_lengths)\n",
    "\n",
    "#When features \"transition\" or \"end\", append total time of that feature (sum of the time differences for each point in a fixation or saccade group)\n",
    "    #Note: you may have to delete the first summation (deduct first point from itself)\n",
    "    #A counter will be necessary to \"reset\" fixations, or omit singular isolated points classified as fixations\n",
    "    \n",
    "#Plot hisogram of each list, with their contained feature durations\n",
    "\n",
    "#print(fix_duration_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Velocity\n",
    "\n",
    "fix_feat_velo = []\n",
    "    \n",
    "for i in range(len(fix_disp_lengths)):\n",
    "        \n",
    "    fix_feat_velo.append(fix_disp_lengths[i]/(fix_duration_lengths[i]/1000000))\n",
    "\n",
    "\n",
    "plt.scatter(np.array(np.array(fix_duration_lengths)/1000000).sum(axis=1),fix_feat_velo, c = 'red')\n",
    "plt.xlabel(\"Fixation Feature Duration\")\n",
    "plt.ylim(0, 25000)\n",
    "plt.xlim(0, 3.5)\n",
    "plt.ylabel(\"Velocity\")\n",
    "plt.title(\"Velocity v. Time (Fixation Features)\")\n",
    "plt.savefig(\"Fixations_feat_velo\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_fix = []\n",
    "y_fix = []\n",
    "\n",
    "x_sac = []\n",
    "y_sac = []\n",
    "\n",
    "t_stamps = test.iloc[:, 0:1].values\n",
    "\n",
    "#print(t_stamps)\n",
    "\n",
    "sac_timestamp = []\n",
    "fix_timestamp = []\n",
    "\n",
    "leg = int(len(f_type))\n",
    "print(leg)\n",
    "\n",
    "for i in range (leg):\n",
    "    if f_type[i] == 'Fixation':\n",
    "        x_fix.append(x_val[i])\n",
    "        y_fix.append(y_val[i])\n",
    "        fix_timestamp.append(t_stamps[i])\n",
    "        \n",
    "    elif f_type[i] == 'Saccade':\n",
    "        x_sac.append(x_val[i])\n",
    "        y_sac.append(y_val[i])\n",
    "        sac_timestamp.append(t_stamps[i])\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(\"X/Y Fixation Points\")\n",
    "\n",
    "#print(x_fix)\n",
    "#print(y_fix)\n",
    "\n",
    "print(\"X/Y Saccade Points\")\n",
    "\n",
    "#print(x_sac)\n",
    "#print(y_sac)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-briefs",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
